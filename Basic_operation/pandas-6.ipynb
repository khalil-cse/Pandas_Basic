{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd382f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration\n",
      "0    Spark  20000    30day\n",
      "1  PySpark  25000   40days\n",
      "2   Hadoop  26000   35days\n",
      "3   Python  22000   40days\n",
      "4   pandas  24000   60days\n",
      "5   Oracle  21000   50days\n",
      "6     Java  22000   55days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "technologies = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"pandas\",\"Oracle\",\"Java\"],\n",
    "    'Fee' :[20000,25000,26000,22000,24000,21000,22000],\n",
    "    'Duration':['30day', '40days' ,'35days', '40days', '60days', '50days', '55days']\n",
    "              })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a9bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20000 Spark\n",
      "1 25000 PySpark\n",
      "2 26000 Hadoop\n",
      "3 22000 Python\n",
      "4 24000 pandas\n",
      "5 21000 Oracle\n",
      "6 22000 Java\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate all rows using DataFrame.iterrows()\n",
    "for index, row in df.iterrows():\n",
    "    print (index,row[\"Fee\"], row[\"Courses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1e9a162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data For First Row :\n",
      "Courses     Spark\n",
      "Fee         20000\n",
      "Duration    30day\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Row contains the column name and data\n",
    "row = next(df.iterrows())[1]\n",
    "print(\"Data For First Row :\")\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ec7e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x248dce3eef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntax DataFrame.itertuples()\n",
    "df.itertuples(index=True, name='Pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81266fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame:\n",
      "     Courses    Fee Duration\n",
      "r1    Spark  20000   30days\n",
      "r2  PySpark  25000   40days\n",
      "r3   Python  22000   35days\n",
      "r4   pandas  30000   50days\n",
      "Second DataFRame:\n",
      "    Courses  Discount\n",
      "r1   Spark      2000\n",
      "r6    Java      2300\n",
      "r3  Python      1200\n",
      "r5      Go      2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Python\",\"pandas\"],\n",
    "    'Fee' :[20000,25000,22000,30000],\n",
    "    'Duration':['30days','40days','35days','50days'],\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4']\n",
    "df1 = pd.DataFrame(technologies,index=index_labels)\n",
    "print(\"First DataFrame:\\n\", df1)\n",
    "technologies2 = {\n",
    "    'Courses':[\"Spark\",\"Java\",\"Python\",\"Go\"],\n",
    "    'Discount':[2000,2300,1200,2000]\n",
    "              }\n",
    "index_labels2=['r1','r6','r3','r5']\n",
    "df2 = pd.DataFrame(technologies2,index=index_labels2)\n",
    "print(\"Second DataFRame:\\n\", df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3902c80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas join \n",
    "#df3=df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "#print(\"After joining two DataFrames:\\n\", df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40c3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Inner join DataFrames\n",
    "# df3=df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how='inner')\n",
    "# print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d23f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Right join DataFrames\n",
    "# df3=df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how='right')\n",
    "# print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12140543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas outer join DataFrames\n",
    "# df3=df1.join(df2, lsuffix=\"_left\", rsuffix=\"_right\", how='outer')\n",
    "# print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17110ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas join on columns\n",
    "# df3=df1.set_index('Courses').join(df2.set_index('Courses'), how='inner')\n",
    "# print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b05d6703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging the two DataFrames:\n",
      "   Courses    Fee Duration  Discount\n",
      "0   Spark  20000   30days      2000\n",
      "1  Python  22000   35days      1200\n"
     ]
    }
   ],
   "source": [
    "# Using pandas.merge()\n",
    "df3= pd.merge(df1,df2)\n",
    "\n",
    "# Using DataFrame.merge()\n",
    "df3=df1.merge(df2)\n",
    "print(\"After merging the two DataFrames:\\n\", df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046e9ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DataFrame:\n",
      "    Courses    Fee\n",
      "0    Spark  20000\n",
      "1  PySpark  25000\n",
      "2   Python  22000\n",
      "3   pandas  24000\n",
      "SEcond DataFrame:\n",
      "     Courses    Fee\n",
      "0    Pandas  25000\n",
      "1    Hadoop  25200\n",
      "2  Hyperion  24500\n",
      "3      Java  24900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Courses': [\"Spark\",\"PySpark\",\"Python\",\"pandas\"],\n",
    "                    'Fee' : [20000,25000,22000,24000]})\n",
    "\n",
    "df1 = pd.DataFrame({'Courses': [\"Pandas\",\"Hadoop\",\"Hyperion\",\"Java\"],\n",
    "                    'Fee': [25000,25200,24500,24900]})\n",
    "print(\"First DataFrame:\\n\", df)\n",
    "print(\"SEcond DataFrame:\\n\", df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293e12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
