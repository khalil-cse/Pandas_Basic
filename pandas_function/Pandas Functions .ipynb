{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d254b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r4   Python  22000   40days      2500\n",
      "r5   pandas  24000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "# Pandas.DataFrame.loc[] Syntax & Usage\n",
    "import pandas as pd\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"pandas\"],\n",
    "    'Fee' :[20000,25000,26000,22000,24000],\n",
    "    'Duration':['30day','40days','35days','40days','60days'],\n",
    "    'Discount':[1000,2300,1200,2500,2000]\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4','r5']\n",
    "df = pd.DataFrame(technologies,index=index_labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bf0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses     PySpark\n",
      "Fee           25000\n",
      "Duration     40days\n",
      "Discount       2300\n",
      "Name: r2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Row by Label\n",
    "print(df.loc['r2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39caf429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1      Spark\n",
      "r2    PySpark\n",
      "r3     Hadoop\n",
      "r4     Python\n",
      "r5     pandas\n",
      "Name: Courses, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Column by label\n",
    "print(df.loc[:, \"Courses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9f2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Rows by Label\n",
    "print(df.loc[['r2','r3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd208ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r4   Python  22000   40days      2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select Rows Between two Index Labels\n",
    "# Includes both r1 and r4 rows\n",
    "print(df.loc['r1':'r4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df55048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fee Duration  Discount\n",
      "r1  20000    30day      1000\n",
      "r2  25000   40days      2300\n",
      "r3  26000   35days      1200\n",
      "r4  22000   40days      2500\n",
      "r5  24000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "# Select Columns between two Labels\n",
    "# Include both 'Fee' and 'Discount' columns\n",
    "print(df.loc[:,'Fee':'Discount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c40013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "r1   Spark  20000    30day      1000\n",
      "r3  Hadoop  26000   35days      1200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select Alternate rows By indeces\n",
    "print(df.loc['r1':'r4':2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6c517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r5   pandas  24000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "# Using Conditions\n",
    "print(df.loc[df['Fee'] >= 24000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59a437",
   "metadata": {},
   "source": [
    "### pandas.DataFrame.iloc[] Syntax & Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89513054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r4   Python  22000   40days      2500\n",
      "r5   pandas  24000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"pandas\"],\n",
    "    'Fee' :[20000,25000,26000,22000,24000],\n",
    "    'Duration':['30day','40days','35days','40days','60days'],\n",
    "    'Discount':[1000,2300,1200,2500,2000]\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4','r5']\n",
    "df = pd.DataFrame(technologies,index=index_labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d060d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses     PySpark\n",
      "Fee           25000\n",
      "Duration     40days\n",
      "Discount       2300\n",
      "Name: r2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select Single Row by Index\n",
    "print(df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c52920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Rows by Index\n",
    "print(df.iloc[[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488e877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee  Discount\n",
      "r1    Spark  20000      1000\n",
      "r2  PySpark  25000      2300\n",
      "r3   Hadoop  26000      1200\n",
      "r4   Python  22000      2500\n",
      "r5   pandas  24000      2000\n"
     ]
    }
   ],
   "source": [
    "# Select Multiple Columns by Index\n",
    "print(df.iloc[:, [0,1,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3246a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r1    Spark  20000    30day      1000\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r4   Python  22000   40days      2500\n"
     ]
    }
   ],
   "source": [
    "# Select Rows Between two Indexs\n",
    "# Includes Index 0 & Execludes 4\n",
    "print(df.iloc[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45644d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "r1   Spark  20000    30day      1000\n",
      "r3  Hadoop  26000   35days      1200\n"
     ]
    }
   ],
   "source": [
    "# Select Alternate rows By Index\n",
    "print(df.iloc[0:4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a6835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses    Fee Duration  Discount\n",
      "r2  PySpark  25000   40days      2300\n",
      "r3   Hadoop  26000   35days      1200\n",
      "r5   pandas  24000   60days      2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# By Condition\n",
    "print(df.iloc[list(df['Fee'] >= 24000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bb5c8",
   "metadata": {},
   "source": [
    "### filter() Syntax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c1cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration\n",
      "0    Spark  22000   30days\n",
      "1  PySpark  25000   50days\n",
      "2    Spark  23000   30days\n",
      "3     Java  24000   60days\n",
      "4  PySpark  26000   35days\n",
      "5      PHP  27000   30days\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "import pandas as pd\n",
    "technologies= {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Spark\",\"Java\",\"PySpark\",\"PHP\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,27000],\n",
    "    'Duration':['30days','50days','30days','60days','35days','30days']\n",
    "          }\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd6dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee\n",
      "0    Spark  22000\n",
      "1  PySpark  25000\n",
      "2    Spark  23000\n",
      "3     Java  24000\n",
      "4  PySpark  26000\n",
      "5      PHP  27000\n"
     ]
    }
   ],
   "source": [
    "# Filter columns\n",
    "df2=df.filter(items=['Courses','Fee'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b045e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Duration\n",
      "0   30days\n",
      "1   50days\n",
      "2   30days\n",
      "3   60days\n",
      "4   35days\n",
      "5   30days\n"
     ]
    }
   ],
   "source": [
    "# Filter Columns using like param\n",
    "df2 = df.filter(like='ration', axis=1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd00919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses\n",
      "0    Spark\n",
      "1  PySpark\n",
      "2    Spark\n",
      "3     Java\n",
      "4  PySpark\n",
      "5      PHP\n"
     ]
    }
   ],
   "source": [
    "# Filr column names by regex\n",
    "df2 = df.filter(regex='s$', axis=1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eed1c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n",
      "3    Java  24000   60days\n",
      "5     PHP  27000   30days\n"
     ]
    }
   ],
   "source": [
    "# Filter rows by index\n",
    "df2=df.filter(items=[3,5], axis=0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61001c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration\n",
      "4  PySpark  26000   35days\n"
     ]
    }
   ],
   "source": [
    "# Filter row using like\n",
    "df2 = df.filter(like='4', axis=0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16ae9c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Courses    Fee Duration\n",
      "3    Java  24000   60days\n",
      "5     PHP  27000   30days\n"
     ]
    }
   ],
   "source": [
    "# Filter rows by index\n",
    "df2=df.filter(items=[3,5], axis=0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d43f10eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee  Discount Duration\n",
      "0    Spark  22000      1500   30days\n",
      "1  PySpark  25000      1000   50days\n",
      "2    Spark  23000      1200   30days\n",
      "3   Python  24000       800   35days\n",
      "4  PySpark  26000      1300   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies= {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Spark\",\"Python\",\"PySpark\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000],\n",
    "    'Discount':[1500,1000,1200,800,1300],\n",
    "    'Duration':['30days','50days','30days','35days','40days']\n",
    "          }\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beefaa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee  Discount Duration\n",
      "0      NaN      NaN       NaN      NaN\n",
      "1  PySpark  25000.0    1000.0   50days\n",
      "2      NaN      NaN       NaN      NaN\n",
      "3   Python  24000.0     800.0   35days\n",
      "4  PySpark  26000.0    1300.0   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Default example\n",
    "df2=df.where(df.Fee > 23000)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4548c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Discount Duration\n",
      "0       NA     NA       NA       NA\n",
      "1  PySpark  25000     1000   50days\n",
      "2       NA     NA       NA       NA\n",
      "3   Python  24000      800   35days\n",
      "4  PySpark  26000     1300   40days\n"
     ]
    }
   ],
   "source": [
    "# Use other param\n",
    "df2=df.where(df.Fee > 23000,'NA')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1d3c72c",
   "metadata": {},
   "source": [
    "# Updating on existing DataFrame\n",
    "df.where(cond1 & cond2, 'NA', inplace=True) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cc6bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create DataFrame:\n",
      "        Fee Duration\n",
      "0  22000.0   30days\n",
      "1  25000.0   50days\n",
      "2  23000.0   30days\n",
      "3      NaN   35days\n",
      "4  26000.0   40days\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a pandas DataFrame.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies= {\n",
    "    'Fee' :[22000,25000,23000,np.NaN,26000],\n",
    "    'Duration':['30days','50days','30days','35days','40days']\n",
    "          }\n",
    "df = pd.DataFrame(technologies)\n",
    "print(\"Create DataFrame:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76035cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying map to specific column:\n",
      "        Fee Duration\n",
      "0  19800.0   30days\n",
      "1  22500.0   50days\n",
      "2  20700.0   30days\n",
      "3      NaN   35days\n",
      "4  23400.0   40days\n"
     ]
    }
   ],
   "source": [
    "# Using Lambda Function\n",
    "df['Fee'] = df['Fee'].map(lambda x: x - (x*10/100))\n",
    "print(\"After applying map to specific column:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32e7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create DataFrame:\n",
      "    Courses    Fee Duration\n",
      "0    Spark  22000   30days\n",
      "1  PySpark  25000   50days\n",
      "2    Spark  23000   30days\n",
      "3   Python  24000   35days\n",
      "4  PySpark  26000      NaN\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Spark\",\"Python\",\"PySpark\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000],\n",
    "    'Duration':['30days','50days','30days','35days','NaN']\n",
    "          }\n",
    "df = pd.DataFrame(technologies)\n",
    "print(\"Create DataFrame:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d821ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After replacing a value with another value:\n",
      "         Courses    Fee Duration\n",
      "0  Apache Spark  22000   30days\n",
      "1       PySpark  25000   50days\n",
      "2  Apache Spark  23000   30days\n",
      "3        Python  24000   35days\n",
      "4       PySpark  26000      NaN\n"
     ]
    }
   ],
   "source": [
    "# Replace column value\n",
    "df2 = df.replace('Spark','Apache Spark')\n",
    "print(\"After replacing a value with another value:\\n\", df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "506c4f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount    \n",
      "r1    Spark  20000.0    30day     1000 NaN\n",
      "r2  PySpark  25000.0   40days      NaN NaN\n",
      "r3   Hadoop  26000.0   35days     1200 NaN\n",
      "r4   Python  23093.0   45days     2500 NaN\n",
      "r5   pandas  24000.0      NaN      NaT NaN\n",
      "        NaN      NaN      NaN      NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "technologies = {\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"pandas\",np.nan],\n",
    "    'Fee' :[20000,25000,26000,23093,24000,np.nan],\n",
    "    'Duration':['30day','40days','35days','45days',np.nan,np.nan],\n",
    "    'Discount':[1000,np.nan,1200,2500,pd.NaT,np.nan],\n",
    "    '':[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "              }\n",
    "index_labels=['r1','r2','r3','r4','r5','']\n",
    "df = pd.DataFrame(technologies,index=index_labels)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f84e73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount    \n",
      "r1    Spark  20000.0    30day     1000 NaN\n",
      "r2  PySpark  25000.0   40days      NaN NaN\n",
      "r3   Hadoop  26000.0   35days     1200 NaN\n",
      "r4   Python  23093.0   45days     2500 NaN\n",
      "r5   pandas  24000.0      NaN      NaT NaN\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that has all Nan Values\n",
    "df = df.dropna(how='all')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c00a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount\n",
      "r1    Spark  20000.0    30day     1000\n",
      "r2  PySpark  25000.0   40days      NaN\n",
      "r3   Hadoop  26000.0   35days     1200\n",
      "r4   Python  23093.0   45days     2500\n",
      "r5   pandas  24000.0      NaN      NaT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Drop columns that has all Nan Values\n",
    "df = df.dropna(how='all',axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff37643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses      Fee Duration Discount\n",
      "r1   Spark  20000.0    30day     1000\n",
      "r3  Hadoop  26000.0   35days     1200\n",
      "r4  Python  23093.0   45days     2500\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that contains nan values\n",
    "df2=df.dropna()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e352f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Courses      Fee Duration Discount\n",
      "r1    Spark  20000.0    30day     1000\n",
      "r2  PySpark  25000.0   40days      NaN\n",
      "r3   Hadoop  26000.0   35days     1200\n",
      "r4   Python  23093.0   45days     2500\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that has NaN values on selected columns\n",
    "df2=df.dropna(subset=['Courses','Duration'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e2b541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>40days</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>35days</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>Python</td>\n",
       "      <td>23093.0</td>\n",
       "      <td>45days</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>pandas</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Courses      Fee Duration Discount\n",
       "r1    Spark  20000.0    30day     1000\n",
       "r2  PySpark  25000.0   40days      NaN\n",
       "r3   Hadoop  26000.0   35days     1200\n",
       "r4   Python  23093.0   45days     2500\n",
       "r5   pandas  24000.0      NaN      NaT"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2671e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With threshold, \n",
    "# Keep only the rows with at least 2 non-NA values.\n",
    "df2=df.dropna(thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69bc0b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>PySpark</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>40days</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>Hadoop</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>35days</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>Python</td>\n",
       "      <td>23093.0</td>\n",
       "      <td>45days</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Courses      Fee Duration Discount\n",
       "r1    Spark  20000.0    30day     1000\n",
       "r2  PySpark  25000.0   40days      NaN\n",
       "r3   Hadoop  26000.0   35days     1200\n",
       "r4   Python  23093.0   45days     2500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb159016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Courses</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>Spark</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>30day</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Courses      Fee Duration Discount\n",
       "r1   Spark  20000.0    30day     1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(-3) #Use negative numbers for N to get the rows except for N rows from the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbaf23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a9eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
